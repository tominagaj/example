{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Anaconda環境下で動作可能です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mne_rsa'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msb\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmne_rsa\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'mne_rsa'"
     ]
    }
   ],
   "source": [
    "import mne # mneライブラリ\n",
    "import numpy as np # numpy: 数値計算ライブラリ\n",
    "# print(__doc__)\n",
    "import matplotlib # matplotlib: 図表示ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Qt5Agg')\n",
    "%matplotlib qt5\n",
    "from mne import io, Epochs, read_epochs\n",
    "from scipy.spatial.distance import cdist, squareform\n",
    "import matplotlib.font_manager as fm\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import mne_rsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 読み込んだデータの\"info\"情報の確認\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 読み込んだデータの測定値の読み込み\n",
    "data = raw.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# データ構造を確認\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 正しい解析のため、測定データの中身を修正する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 測定値の校正係数の二重掛けを補正する\n",
    "range_factor = 100.0 / 4.5\n",
    "raw_length = len(raw)\n",
    "channel_length = len(raw.info[\"chs\"])\n",
    "raw_array = np.zeros((channel_length, raw_length))\n",
    "for i in range(channel_length):\n",
    "    cal_factor = raw.info[\"chs\"][i][\"cal\"]\n",
    "    if i < 64:\n",
    "        raw_array[i] = (data[i] / cal_factor) * range_factor\n",
    "    else:\n",
    "        raw_array[i] = data[i]\n",
    "raw_new = mne.io.RawArray(raw_array, raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_new.info[\"chs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# コイル番号を解析可能なコイル番号に上書きする。\n",
    "for ch in raw_new.info[\"chs\"]:\n",
    "    ch[\"coil_type\"] = 5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 上書きされたことを確認\n",
    "raw_new.info[\"chs\"][0][\"coil_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 修正したデータを新たにFIFF形式で出力する\n",
    "raw_new.save(modified_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 上で作成した修正した測定データ読み込み\n",
    "## data_pathは読み込みたいデータのディレクトリに合わせて編集ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/jiontominaga/ThesisProject/data/5014/MEG_5014/5014_02_modified_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 1364499 =      0.000 ...   545.800 secs\n",
      "Ready.\n",
      "Reading 0 ... 1364499  =      0.000 ...   545.800 secs...\n"
     ]
    }
   ],
   "source": [
    "data_path = modified_path\n",
    "raw = mne.io.read_raw_fif(data_path, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# データをプロットすることで確認\n",
    "# raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# STIMチャンネルにノイズがあり、そのノイズ除去を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = raw.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ノイズとする閾値を設定するため、そのオーダーを確認する\n",
    "time_start = 0.0\n",
    "time_stop = 700\n",
    "# time_stop = 768.0\n",
    "start, stop = raw.time_as_index([time_start, time_stop])\n",
    "# plt.plot(np.arange(start, stop)/1000.0, data[64][start:stop])\n",
    "# plt.plot(np.arange(start, stop)/1000.0, data[65][start:stop])\n",
    "# plt.plot(np.arange(start, stop)/1000.0, data[66][start:stop])\n",
    "# plt.plot(np.arange(start, stop)/1000.0, data[67][start:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ノイズとする閾値を1.0に設定し、STIM1～4のノイズを除去する\n",
    "for cnt in [64, 65, 66, 67]:\n",
    "    time_index = np.where(data[cnt] < 1.0)\n",
    "    data[cnt][time_index] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=68, n_times=1364500\n",
      "    Range : 0 ... 1364499 =      0.000 ...   545.800 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# ノイズ除去したデータで新たにデータフレーム作成\n",
    "raw = mne.io.RawArray(data, raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# データをプロットすることで確認\n",
    "# raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# STIMのノイズ除去したデータで解析を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Info | 10 non-empty values\n acq_pars: SHI MEG\n bads: []\n ch_names: C03, L04, L10, L02, L18, C02, L34, L26, L28, L42, L08, L48, L22, ...\n chs: 64 Gradiometers, 4 Stimulus\n custom_ref_applied: False\n file_id: 4 items (dict)\n highpass: 0.1 Hz\n lowpass: 1132.5 Hz\n meas_date: 1970-01-01 00:00:00 UTC\n meas_id: 4 items (dict)\n nchan: 68\n projs: []\n sfreq: 2500.0 Hz\n>",
      "text/html": "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n    <tr>\n        <th>Measurement date</th>\n        \n        <td>January 01, 1970  00:00:00 GMT</td>\n        \n    </tr>\n    <tr>\n        <th>Experimenter</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n        <th>Participant</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n    <tr>\n        <th>Digitized points</th>\n        \n        <td>Not available</td>\n        \n    </tr>\n    <tr>\n        <th>Good channels</th>\n        <td>64 Gradiometers, 4 Stimulus</td>\n    </tr>\n    <tr>\n        <th>Bad channels</th>\n        <td>None</td>\n    </tr>\n    <tr>\n        <th>EOG channels</th>\n        <td>Not available</td>\n    </tr>\n    <tr>\n        <th>ECG channels</th>\n        <td>Not available</td>\n    \n    <tr>\n        <th>Sampling frequency</th>\n        <td>2500.00 Hz</td>\n    </tr>\n    \n    \n    <tr>\n        <th>Highpass</th>\n        <td>0.10 Hz</td>\n    </tr>\n    \n    \n    <tr>\n        <th>Lowpass</th>\n        <td>1132.50 Hz</td>\n    </tr>\n    \n    \n</table>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10000000149011612\n",
      "1132.5\n"
     ]
    }
   ],
   "source": [
    "print(raw.info['highpass'])\n",
    "print(raw.info['lowpass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 82501 samples (33.000 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "<RawArray | 68 x 1364500 (545.8 s), ~708.0 MB, data loaded>",
      "text/html": "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n    <tr>\n        <th>Measurement date</th>\n        \n        <td>January 01, 1970  00:00:00 GMT</td>\n        \n    </tr>\n    <tr>\n        <th>Experimenter</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n        <th>Participant</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n    <tr>\n        <th>Digitized points</th>\n        \n        <td>Not available</td>\n        \n    </tr>\n    <tr>\n        <th>Good channels</th>\n        <td>64 Gradiometers, 4 Stimulus</td>\n    </tr>\n    <tr>\n        <th>Bad channels</th>\n        <td>None</td>\n    </tr>\n    <tr>\n        <th>EOG channels</th>\n        <td>Not available</td>\n    </tr>\n    <tr>\n        <th>ECG channels</th>\n        <td>Not available</td>\n    \n    <tr>\n        <th>Sampling frequency</th>\n        <td>2500.00 Hz</td>\n    </tr>\n    \n    \n    <tr>\n        <th>Highpass</th>\n        <td>0.10 Hz</td>\n    </tr>\n    \n    \n    <tr>\n        <th>Lowpass</th>\n        <td>40.00 Hz</td>\n    </tr>\n    \n    \n    \n    <tr>\n        <th>Duration</th>\n        <td>00:09:06 (HH:MM:SS)</td>\n    </tr>\n</table>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全64チャンネルの測定結果のノイズ除去\n",
    "raw.filter(l_freq=0.1, h_freq=40.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing orphaned offset at the beginning of the file.\n",
      "48 events found\n",
      "Event IDs: [4]\n",
      "45 events found\n",
      "Event IDs: [4]\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "39 events found\n",
      "Event IDs: [4]\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "8 events found\n",
      "Event IDs: [4]\n",
      "stim1: (48, 3)\n",
      "stim2: (45, 3)\n",
      "stim3: (39, 3)\n",
      "stim4: (8, 3)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "48 events found\n",
      "Event IDs: [4]\n",
      "45 events found\n",
      "Event IDs: [4]\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "39 events found\n",
      "Event IDs: [4]\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "8 events found\n",
      "Event IDs: [4]\n",
      "stim1: (48, 3)\n",
      "stim2: (45, 3)\n",
      "stim3: (39, 3)\n",
      "stim4: (8, 3)\n"
     ]
    }
   ],
   "source": [
    "# STIM1～3の出力からイベントを定義する\n",
    "# (min_duration=0.002 and min_duration=0.3 won't have difference on the number of events detected)\n",
    "events_stim1 = mne.find_events(raw, stim_channel='STIM1', min_duration=0.3)\n",
    "events_stim2 = mne.find_events(raw, stim_channel='STIM2', min_duration=0.3)\n",
    "events_stim3 = mne.find_events(raw, stim_channel='STIM3', min_duration=0.3)\n",
    "events_stim4 = mne.find_events(raw, stim_channel='STIM1', min_duration=0.6)\n",
    "\n",
    "print(f'stim1: {events_stim1.shape}')\n",
    "print(f'stim2: {events_stim2.shape}')\n",
    "print(f'stim3: {events_stim3.shape}')\n",
    "print(f'stim4: {events_stim4.shape}')\n",
    "\n",
    "#mne.find_events returns arrays of integers with the following structure: [event time in samples, this column can be ignored, event id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 3)\n"
     ]
    }
   ],
   "source": [
    "#Animal (1): STIM1 (events_stim1)\n",
    "events_stim_index = []\n",
    "for value in events_stim1[:,0]:\n",
    "    a = np.where(events_stim2[:,0]==value)[0]\n",
    "    if a.size == 1:\n",
    "        events_stim_index.append(a[0]) #stim(1)(1,2)(1,3)(1,2,3) n stim(1,2)(2)(2,3)(1,2,3) = stim(1,2)(1,2,3)\n",
    "events_temp = np.delete(events_stim1, np.array(events_stim_index), 0) #stim(1)(1,2)(1,3)(1,2,3) - stim(1,2)(1,2,3) = stim(1)(1,3)\n",
    "events_stim_index = []\n",
    "for value in events_stim3[:,0]:\n",
    "    a = np.where(events_temp[:,0]==value)[0] #stim(1)(1,3) n stim(1,3)(2,3)(3)(1,2,3) = stim(1,3)\n",
    "    if a.size == 1:\n",
    "        events_stim_index.append(a[0]) # [stim(1,3)]\n",
    "events_condition1 = np.delete(events_temp, np.array(events_stim_index), 0) # stim(1)(1,3) - stim(1,3) = stim(1)\n",
    "print(events_condition1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 3)\n"
     ]
    }
   ],
   "source": [
    "#Human (2): STIM2 (events_stim2)\n",
    "events_stim_index = []\n",
    "for value in events_stim1[:,0]:\n",
    "    a = np.where(events_stim2[:,0]==value)[0]\n",
    "    if a.size == 1:\n",
    "        events_stim_index.append(a[0]) #stim(1)(1,2)(1,3)(1,2,3) n stim(1,2)(2)(2,3)(1,2,3) = stim(1,2)(1,2,3)\n",
    "events_temp = np.delete(events_stim2, np.array(events_stim_index), 0) #stim(1,2)(2)(2,3)(1,2,3) - stim(1,2)(1,2,3) = stim(2)(2,3)\n",
    "events_stim_index = []\n",
    "for value in events_stim3[:,0]:\n",
    "    a = np.where(events_temp[:,0]==value)[0] #stim(2)(2,3) n stim(1,3)(2,3)(3)(1,2,3) = stim(2,3)\n",
    "    if a.size == 1:\n",
    "        events_stim_index.append(a[0]) # [stim(2,3)]\n",
    "events_condition2 = np.delete(events_temp, np.array(events_stim_index), 0) # stim(2)(2,3) - stim(2,3) = stim(2)\n",
    "print(events_condition2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 3)\n"
     ]
    }
   ],
   "source": [
    "#Body Parts (3): STIM1, STIM2 (events_stim1)(events_stim2)\n",
    "intersect = np.intersect1d(events_stim1[:,0], events_stim2[:,0]) #stim(1)(1,2)(1,3)(1,2,3) n stim(1,2)(2)(2,3)(1,2,3) = stim(1,2)(1,2,3)\n",
    "\n",
    "events_stim_index = np.zeros_like(intersect) #empty array with shape of stim(1,2)(1,2,3)\n",
    "\n",
    "for cnt in range(len(intersect)):\n",
    "    events_stim_index[cnt] = np.where(events_stim1[:,0]==intersect[cnt])[0][0] #stim(1)(1,2)(1,3)(1,2,3) n stim(1,2)(1,2,3) = stim(1,2)(1,2,3) (stores it in events_stim_index)\n",
    "\n",
    "events_stim_temp = events_stim1[events_stim_index] #stim(1,2)(1,2,3) *get data corresponding to indices in events_stim_index\n",
    "\n",
    "events_stim_index = []\n",
    "for value in events_stim3[:,0]: #choose event_stim that hasn't been used previously.\n",
    "    a = np.where(events_stim_temp[:,0]==value)[0] #stim(1,2)(1,2,3) n stim(1,3)(2,3)(3)(1,2,3) = stim(1,2,3)\n",
    "    if a.size == 1:\n",
    "        events_stim_index.append(a[0]) #stim(1,2,3)\n",
    "events_stim_index = np.array(events_stim_index) #stim(1,2,3) (np.array)\n",
    "events_condition3 = np.delete(events_stim_temp, events_stim_index, 0) #stim(1,2)(1,2,3) - stim(1,2,3) = stim(1,2)\n",
    "print(events_condition3.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "#Vehicle (4): STIM3 (events_stim3)\n",
    "events_stim_index = []\n",
    "for value in events_stim1[:,0]:\n",
    "    a = np.where(events_stim3[:,0]==value)[0]\n",
    "    if a.size == 1:\n",
    "        events_stim_index.append(a[0]) #stim(1)(1,2)(1,3)(1,2,3) n stim(1,3)(2,3)(3)(1,2,3) = stim(1,3)(1,2,3)\n",
    "events_temp = np.delete(events_stim3, np.array(events_stim_index), 0) #stim(1,3)(2,3)(3)(1,2,3) - stim(1,3)(1,2,3) = stim(2,3)(3)\n",
    "events_stim_index = []\n",
    "for value in events_stim2[:,0]:\n",
    "    a = np.where(events_temp[:,0]==value)[0] #stim(2,3)(3) n stim(1,2)(2)(2,3)(1,2,3) = stim(2,3)\n",
    "    if a.size == 1:\n",
    "        events_stim_index.append(a[0]) # [stim(2,3)]\n",
    "events_condition4 = np.delete(events_temp, np.array(events_stim_index), 0) # stim(2,3)(3) - stim(2,3) = stim(3)\n",
    "print(events_condition4.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "#Food (5): STIM1, STIM3 (events_stim1)(events_stim3)\n",
    "intersect = np.intersect1d(events_stim1[:,0], events_stim3[:,0]) #stim(1)(1,2)(1,3)(1,2,3) n stim(1,3)(2,3)(3)(1,2,3) = stim(1,3)(1,2,3)\n",
    "\n",
    "events_stim_index = np.zeros_like(intersect) #empty array with shape of stim(1,3)(1,2,3)\n",
    "\n",
    "for cnt in range(len(intersect)):\n",
    "    events_stim_index[cnt] = np.where(events_stim1[:,0]==intersect[cnt])[0][0] #stim(1)(1,2)(1,3)(1,2,3) n stim(1,3)(1,2,3) = stim(1,3)(1,2,3) (stores corresponding indices from events_stim1 to events_stim_index)\n",
    "\n",
    "events_stim_temp = events_stim1[events_stim_index] #stim(1,3)(1,2,3) *get data corresponding to indices in events_stim_index\n",
    "\n",
    "events_stim_index = []\n",
    "for value in events_stim2[:,0]: #choose event_stim that hasn't been used previously.\n",
    "    a = np.where(events_stim_temp[:,0]==value)[0] #stim(1,3)(1,2,3) n stim(1,2)(2)(2,3)(1,2,3) = stim(1,2,3)\n",
    "    if a.size == 1:\n",
    "        events_stim_index.append(a[0]) #stim(1,2,3)\n",
    "events_stim_index = np.array(events_stim_index) #stim(1,2,3) (np.array)\n",
    "events_condition5 = np.delete(events_stim_temp, events_stim_index, 0) #stim(1,3)(1,2,3) - stim(1,2,3) = stim(1,3)\n",
    "print(events_condition5.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 3)\n"
     ]
    }
   ],
   "source": [
    "#Inanimate (6): STIM2, STIM3 (events_stim2)(events_stim3)\n",
    "intersect = np.intersect1d(events_stim2[:,0], events_stim3[:,0]) #stim(1,2)(2)(2,3)(1,2,3) n stim(1,3)(2,3)(3)(1,2,3) = stim(2,3)(1,2,3)\n",
    "\n",
    "events_stim_index = np.zeros_like(intersect) #empty array with shape of stim(2,3)(1,2,3)\n",
    "\n",
    "for cnt in range(len(intersect)):\n",
    "    events_stim_index[cnt] = np.where(events_stim2[:,0]==intersect[cnt])[0][0] #stim(1,2)(2)(2,3)(1,2,3) n stim(2,3)(1,2,3) = stim(2,3)(1,2,3) (stores corresponding indices from events_stim1 to events_stim_index)\n",
    "\n",
    "events_stim_temp = events_stim2[events_stim_index] #stim(2,3)(1,2,3) *get data corresponding to indices in events_stim_index\n",
    "\n",
    "events_stim_index = []\n",
    "for value in events_stim1[:,0]: #choose event_stim that hasn't been used previously.\n",
    "    a = np.where(events_stim_temp[:,0]==value)[0] #stim(2,3)(1,2,3) n stim(1)(1,2)(1,3)(1,2,3) = stim(1,2,3)\n",
    "    if a.size == 1:\n",
    "        events_stim_index.append(a[0]) #stim(1,2,3)\n",
    "events_stim_index = np.array(events_stim_index) #stim(1,2,3) (np.array)\n",
    "events_condition6 = np.delete(events_stim_temp, events_stim_index, 0) #stim(2,3)(1,2,3) - stim(1,2,3) = stim(2,3)\n",
    "print(events_condition6.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "#Man-made Place (7): STIM1, STIM2, STIM3 (events_stim1)(events_stim2)(events_stim3)\n",
    "\n",
    "intersect = np.intersect1d(events_stim1[:,0], events_stim2[:,0]) #stim(1)(1,2)(1,3)(1,2,3) n stim(1,2)(2)(2,3)(1,2,3) = stim(1,2)(1,2,3)\n",
    "intersect2 = np.intersect1d(intersect, events_stim3[:,0]) #stim(1,2)(1,2,3) n stim(1,3)(2,3)(3)(1,2,3) = stim(1,2,3)\n",
    "\n",
    "events_stim_index2 = np.zeros_like(intersect2) #empty array of size stim(1,2,3)\n",
    "\n",
    "for cnt in range(len(intersect2)):\n",
    "    events_stim_index2[cnt] = np.where(events_stim1[:,0]==intersect2[cnt])[0][0] #get indices of stim(1,2,3) within stim1\n",
    "\n",
    "events_stim_temp2 = events_stim1[events_stim_index2] #get data of stim(1,2,3) from stim1\n",
    "\n",
    "events_condition7 = events_stim_temp2\n",
    "print(events_condition7.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# #Man-made Place***** (7): STIM1, STIM2, STIM3 (events_stim1)(events_stim2)(events_stim3)\n",
    "#\n",
    "# intersect = np.intersect1d(events_stim1[:,0], events_stim2[:,0]) #stim(1)(1,2)(1,3)(1,2,3) n stim(1,2)(2)(2,3)(1,2,3) = stim(1,2)(1,2,3)\n",
    "# intersect2 = np.intersect1d(events_stim1[:,0], events_stim3[:,0]) #stim(1)(1,2)(1,3)(1,2,3) n stim(1,3)(2,3)(3)(1,2,3) = stim(1,3)(1,2,3)\n",
    "# intersect3 = np.intersect1d(intersect, intersect2)\n",
    "#\n",
    "# events_stim_index = np.zeros_like(intersect3)\n",
    "#\n",
    "# for cnt in range(len(intersect3)):\n",
    "#     events_stim_index[cnt] = np.where(events_stim1[:,0]==intersect3[cnt])[0][0] #get indices of stim(1,2,3) within stim1\n",
    "#\n",
    "# events_stim_temp = events_stim1[events_stim_index] #get data of stim(1,2,3) from stim1\n",
    "#\n",
    "# events_condition7 = events_stim_temp\n",
    "# print(events_condition7.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "#Tools/Artifacts (8): STIM1* (events_stim4)\n",
    "events_condition8 = events_stim4\n",
    "print(events_condition8.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(18, 13, 11, 8, 10, 13, 8, 8)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events_condition1),len(events_condition2),len(events_condition3), len(events_condition4),len(events_condition5),len(events_condition6), len(events_condition7),len(events_condition8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# この後の解析で、測定データから除く数値域を定義する\n",
    "reject = dict(grad = 7000e-13) # T / m (gradiometers)\n",
    "# reject = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "18 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 18 events and 5001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 13 events and 5001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "11 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 11 events and 5001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8 events and 5001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "10 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 10 events and 5001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 13 events and 5001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8 events and 5001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8 events and 5001 original time points ...\n",
      "0 bad epochs dropped\n",
      "(18, 13, 11, 8, 10, 13, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "# イベント行列からエポックの切り出しを行う\n",
    "epochs_condition1 = mne.Epochs(raw=raw, events=events_condition1, tmin=epoch_tmin, tmax=epoch_tmax, preload=True,\\\n",
    "                    baseline=(epoch_base,0), reject=reject)\n",
    "epochs_condition2 = mne.Epochs(raw=raw, events=events_condition2, tmin=epoch_tmin, tmax=epoch_tmax, preload=True,\\\n",
    "                    baseline=(epoch_base,0), reject=reject)\n",
    "epochs_condition3 = mne.Epochs(raw=raw, events=events_condition3, tmin=epoch_tmin, tmax=epoch_tmax, preload=True,\\\n",
    "                    baseline=(epoch_base,0), reject=reject)\n",
    "epochs_condition4 = mne.Epochs(raw=raw, events=events_condition4, tmin=epoch_tmin, tmax=epoch_tmax, preload=True,\\\n",
    "                    baseline=(epoch_base,0), reject=reject)\n",
    "epochs_condition5 = mne.Epochs(raw=raw, events=events_condition5, tmin=epoch_tmin, tmax=epoch_tmax, preload=True,\\\n",
    "                    baseline=(epoch_base,0), reject=reject)\n",
    "epochs_condition6 = mne.Epochs(raw=raw, events=events_condition6, tmin=epoch_tmin, tmax=epoch_tmax, preload=True,\\\n",
    "                    baseline=(epoch_base,0), reject=reject)\n",
    "epochs_condition7 = mne.Epochs(raw=raw, events=events_condition7, tmin=epoch_tmin, tmax=epoch_tmax, preload=True,\\\n",
    "                    baseline=(epoch_base,0), reject=reject)\n",
    "epochs_condition8 = mne.Epochs(raw=raw, events=events_condition8, tmin=epoch_tmin, tmax=epoch_tmax, preload=True,\\\n",
    "                    baseline=(epoch_base,0), reject=reject)\n",
    "epochs_list = (len(epochs_condition1), len(epochs_condition2), len(epochs_condition3), len(epochs_condition4), len(epochs_condition5), len(epochs_condition6), len(epochs_condition7), len(epochs_condition8), )\n",
    "\n",
    "print(epochs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Butterfly plot for Condition1\n",
    "# evoked_condition1 = epochs_condition1.average()\n",
    "# drop_channels = ['C03', 'L48', 'L12', 'L20']\n",
    "# evoked_condition1.drop_channels(drop_channels)\n",
    "#\n",
    "# # バラフライプロットをするためのパラメータ定義\n",
    "# # ts_args = dict(gfp=False, time_unit='ms', ylim=dict(grad=[-70, 60]))\n",
    "# ts_args = dict(gfp=False, time_unit='ms')\n",
    "# topomap_args = dict(sensors=True, time_unit='ms')\n",
    "#\n",
    "# # バタフライプロットとトポマップを表示\n",
    "# title=f'Butterfly_Raw_{exp_type}_Cond1'\n",
    "# fig = evoked_condition1.plot_joint(times='peaks', title=title, ts_args=ts_args, topomap_args=topomap_args)\n",
    "# fig.savefig(f'{title}.png', dpi=300)\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Butterfly plot for Condition2\n",
    "# evoked_condition2 = epochs_condition2.average()\n",
    "# drop_channels = ['C03', 'L48', 'L12', 'L20']\n",
    "# evoked_condition2.drop_channels(drop_channels)\n",
    "#\n",
    "# # バラフライプロットをするためのパラメータ定義\n",
    "# # ts_args = dict(gfp=False, time_unit='ms', ylim=dict(grad=[-70, 60]))\n",
    "# ts_args = dict(gfp=False, time_unit='ms')\n",
    "# topomap_args = dict(sensors=True, time_unit='ms')\n",
    "#\n",
    "# # バタフライプロットとトポマップを表示\n",
    "# title=f'Butterfly_Raw_{exp_type}_Cond2'\n",
    "# fig = evoked_condition2.plot_joint(times=[-0.5, 1.5], title=title, ts_args=ts_args, topomap_args=topomap_args)\n",
    "# fig.savefig(f'{title}.png', dpi=300)\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Butterfly plot for Condition3\n",
    "# evoked_condition3 = epochs_condition3.average()\n",
    "# drop_channels = ['C03', 'L48', 'L12', 'L20']\n",
    "# evoked_condition3.drop_channels(drop_channels)\n",
    "#\n",
    "# # バラフライプロットをするためのパラメータ定義\n",
    "# # ts_args = dict(gfp=False, time_unit='ms', ylim=dict(grad=[-70, 60]))\n",
    "# ts_args = dict(gfp=False, time_unit='ms')\n",
    "# topomap_args = dict(sensors=True, time_unit='ms')\n",
    "#\n",
    "# # バタフライプロットとトポマップを表示\n",
    "# title=f'Butterfly_Raw_{exp_type}_Cond3'\n",
    "# fig = evoked_condition3.plot_joint(times=[-0.5, 1.5], title=title, ts_args=ts_args, topomap_args=topomap_args)\n",
    "# fig.savefig(f'{title}.png', dpi=300)\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Butterfly plot for Condition4\n",
    "# evoked_condition4 = epochs_condition4.average()\n",
    "# drop_channels = ['C03', 'L48', 'L12', 'L20']\n",
    "# evoked_condition4.drop_channels(drop_channels)\n",
    "#\n",
    "# # バラフライプロットをするためのパラメータ定義\n",
    "# # ts_args = dict(gfp=False, time_unit='ms', ylim=dict(grad=[-70, 60]))\n",
    "# ts_args = dict(gfp=False, time_unit='ms')\n",
    "# topomap_args = dict(sensors=True, time_unit='ms')\n",
    "#\n",
    "# # バタフライプロットとトポマップを表示\n",
    "# title=f'Butterfly_Raw_{exp_type}_Cond4'\n",
    "# fig = evoked_condition4.plot_joint(times=[-0.5, 1.5], title=title, ts_args=ts_args, topomap_args=topomap_args)\n",
    "# fig.savefig(f'{title}.png', dpi=300)\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Butterfly plot for Condition5\n",
    "# evoked_condition5 = epochs_condition5.average()\n",
    "# drop_channels = ['C03', 'L48', 'L12', 'L20']\n",
    "# evoked_condition5.drop_channels(drop_channels)\n",
    "#\n",
    "# # バラフライプロットをするためのパラメータ定義\n",
    "# # ts_args = dict(gfp=False, time_unit='ms', ylim=dict(grad=[-70, 60]))\n",
    "# ts_args = dict(gfp=False, time_unit='ms')\n",
    "# topomap_args = dict(sensors=True, time_unit='ms')\n",
    "#\n",
    "# # バタフライプロットとトポマップを表示\n",
    "# title=f'Butterfly_Raw_{exp_type}_Cond5'\n",
    "# fig = evoked_condition5.plot_joint(times=[-0.5, 1.5], title=title, ts_args=ts_args, topomap_args=topomap_args)\n",
    "# fig.savefig(f'{title}.png', dpi=300)\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Butterfly plot for Condition6\n",
    "# evoked_condition6 = epochs_condition6.average()\n",
    "# drop_channels = ['C03', 'L48', 'L12', 'L20']\n",
    "# evoked_condition6.drop_channels(drop_channels)\n",
    "#\n",
    "# # バラフライプロットをするためのパラメータ定義\n",
    "# # ts_args = dict(gfp=False, time_unit='ms', ylim=dict(grad=[-70, 60]))\n",
    "# ts_args = dict(gfp=False, time_unit='ms')\n",
    "# topomap_args = dict(sensors=True, time_unit='ms')\n",
    "#\n",
    "# # バタフライプロットとトポマップを表示\n",
    "# title=f'Butterfly_Raw_{exp_type}_Cond6'\n",
    "# fig = evoked_condition6.plot_joint(times=[-0.5, 1.5], title=title, ts_args=ts_args, topomap_args=topomap_args)\n",
    "# fig.savefig(f'{title}.png', dpi=300)\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Butterfly plot for Condition7\n",
    "# evoked_condition7 = epochs_condition7.average()\n",
    "# drop_channels = ['C03', 'L48', 'L12', 'L20']\n",
    "# evoked_condition7.drop_channels(drop_channels)\n",
    "#\n",
    "# # バラフライプロットをするためのパラメータ定義\n",
    "# # ts_args = dict(gfp=False, time_unit='ms', ylim=dict(grad=[-70, 60]))\n",
    "# ts_args = dict(gfp=False, time_unit='ms')\n",
    "# topomap_args = dict(sensors=True, time_unit='ms')\n",
    "#\n",
    "# # バタフライプロットとトポマップを表示\n",
    "# title=f'Butterfly_Raw_{exp_type}_Cond7'\n",
    "# fig = evoked_condition7.plot_joint(times=[-0.5, 1.5], title=title, ts_args=ts_args, topomap_args=topomap_args)\n",
    "# fig.savefig(f'{title}.png', dpi=300)\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Butterfly plot for Condition8\n",
    "# evoked_condition8 = epochs_condition8.average()\n",
    "# drop_channels = ['C03', 'L48', 'L12', 'L20']\n",
    "# evoked_condition8.drop_channels(drop_channels)\n",
    "#\n",
    "# # バラフライプロットをするためのパラメータ定義\n",
    "# # ts_args = dict(gfp=False, time_unit='ms', ylim=dict(grad=[-70, 60]))\n",
    "# ts_args = dict(gfp=False, time_unit='ms')\n",
    "# topomap_args = dict(sensors=True, time_unit='ms')\n",
    "#\n",
    "# # バタフライプロットとトポマップを表示\n",
    "# title=f'Butterfly_Raw_{exp_type}_Cond8'\n",
    "# fig = evoked_condition8.plot_joint(times=[-0.5, 1.5], title=title, ts_args=ts_args, topomap_args=topomap_args)\n",
    "# fig.savefig(f'{title}.png', dpi=300)\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MEG channels for epochs_condition1: 59\n",
      "Number of MEG channels for epochs_condition2: 59\n",
      "Number of MEG channels for epochs_condition3: 59\n",
      "Number of MEG channels for epochs_condition4: 59\n",
      "Number of MEG channels for epochs_condition5: 59\n",
      "Number of MEG channels for epochs_condition6: 59\n",
      "Number of MEG channels for epochs_condition7: 59\n",
      "Number of MEG channels for epochs_condition8: 59\n"
     ]
    }
   ],
   "source": [
    "epochs_condition1.drop_channels(ch_names=['STIM1', 'STIM2', 'STIM3', 'STIM4'])\n",
    "epochs_condition1.drop_channels(ch_names=['C03', 'L48', 'L32', 'L12', 'L20'])\n",
    "print(f'Number of MEG channels for epochs_condition1: {len(epochs_condition1.ch_names)}')\n",
    "\n",
    "epochs_condition2.drop_channels(ch_names=['STIM1', 'STIM2', 'STIM3', 'STIM4'])\n",
    "epochs_condition2.drop_channels(ch_names=['C03', 'L48', 'L32', 'L12', 'L20'])\n",
    "print(f'Number of MEG channels for epochs_condition2: {len(epochs_condition2.ch_names)}')\n",
    "\n",
    "epochs_condition3.drop_channels(ch_names=['STIM1', 'STIM2', 'STIM3', 'STIM4'])\n",
    "epochs_condition3.drop_channels(ch_names=['C03', 'L48', 'L32', 'L12', 'L20'])\n",
    "print(f'Number of MEG channels for epochs_condition3: {len(epochs_condition3.ch_names)}')\n",
    "\n",
    "epochs_condition4.drop_channels(ch_names=['STIM1', 'STIM2', 'STIM3', 'STIM4'])\n",
    "epochs_condition4.drop_channels(ch_names=['C03', 'L48', 'L32', 'L12', 'L20'])\n",
    "print(f'Number of MEG channels for epochs_condition4: {len(epochs_condition4.ch_names)}')\n",
    "\n",
    "epochs_condition5.drop_channels(ch_names=['STIM1', 'STIM2', 'STIM3', 'STIM4'])\n",
    "epochs_condition5.drop_channels(ch_names=['C03', 'L48', 'L32', 'L12', 'L20'])\n",
    "print(f'Number of MEG channels for epochs_condition5: {len(epochs_condition5.ch_names)}')\n",
    "\n",
    "epochs_condition6.drop_channels(ch_names=['STIM1', 'STIM2', 'STIM3', 'STIM4'])\n",
    "epochs_condition6.drop_channels(ch_names=['C03', 'L48', 'L32', 'L12', 'L20'])\n",
    "print(f'Number of MEG channels for epochs_condition6: {len(epochs_condition6.ch_names)}')\n",
    "\n",
    "epochs_condition7.drop_channels(ch_names=['STIM1', 'STIM2', 'STIM3', 'STIM4'])\n",
    "epochs_condition7.drop_channels(ch_names=['C03', 'L48', 'L32', 'L12', 'L20'])\n",
    "print(f'Number of MEG channels for epochs_condition7: {len(epochs_condition7.ch_names)}')\n",
    "\n",
    "epochs_condition8.drop_channels(ch_names=['STIM1', 'STIM2', 'STIM3', 'STIM4'])\n",
    "epochs_condition8.drop_channels(ch_names=['C03', 'L48', 'L32', 'L12', 'L20'])\n",
    "print(f'Number of MEG channels for epochs_condition8: {len(epochs_condition8.ch_names)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 59, 5001)\n"
     ]
    }
   ],
   "source": [
    "data_cond1 = epochs_condition1.get_data()\n",
    "print(data_cond1.shape)\n",
    "n_epochs, n_channels, n_times = data_cond1.shape\n",
    "\n",
    "for i in range(n_times):\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]]\n",
      "\n",
      " [[27 28 29]\n",
      "  [30 31 32]\n",
      "  [33 34 35]]\n",
      "\n",
      " [[36 37 38]\n",
      "  [39 40 41]\n",
      "  [42 43 44]]]\n",
      "(5, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.arange(45).reshape(5,3,3)\n",
    "print(x)\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "print(x[0,:,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plot bar plots for the averaged epoch spearman's correlation for each channel\n",
    "condition_list = [epochs_condition1, epochs_condition2, epochs_condition3, epochs_condition4, epochs_condition5, epochs_condition6, epochs_condition7, epochs_condition8]\n",
    "\n",
    "for condition in condition_list:\n",
    "    if condition == epochs_condition1:\n",
    "        condition_name = \"Animal\"\n",
    "    elif condition == epochs_condition2:\n",
    "        condition_name = \"Human\"\n",
    "    elif condition == epochs_condition3:\n",
    "        condition_name = \"Body Parts\"\n",
    "    elif condition == epochs_condition4:\n",
    "        condition_name = \"Vehicle\"\n",
    "    elif condition == epochs_condition5:\n",
    "        condition_name = \"Food\"\n",
    "    elif condition == epochs_condition6:\n",
    "        condition_name = \"Inanimate\"\n",
    "    elif condition == epochs_condition7:\n",
    "        condition_name = \"Man-made Place\"\n",
    "    elif condition == epochs_condition8:\n",
    "        condition_name = \"Tools_Artifacts\"\n",
    "\n",
    "    print(f'{condition_name} shape: {condition.get_data().shape}')\n",
    "\n",
    "    import numpy as np\n",
    "    from itertools import combinations\n",
    "    from scipy.stats import spearmanr\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Load epoch data\n",
    "    arr = condition.get_data()\n",
    "\n",
    "    # Get the number of rows\n",
    "    num_rows = arr.shape[0]\n",
    "    num_channels = arr.shape[1]\n",
    "\n",
    "    # Generate all combinations of epoch indices\n",
    "    row_combinations = list(combinations(range(num_rows), 2))\n",
    "    num_combinations = len(row_combinations)\n",
    "\n",
    "    # Initialize the array to store the Spearman correlation coefficients\n",
    "    spearman_channels = np.zeros((num_channels, num_combinations))\n",
    "\n",
    "    # Now you can iterate over the combinations and access the corresponding rows\n",
    "    for ch in range(num_channels):\n",
    "        for i, combo in enumerate(row_combinations):\n",
    "            epoch1, epoch2 = combo\n",
    "            epoch1_data = arr[epoch1][ch]\n",
    "            epoch2_data = arr[epoch2][ch]\n",
    "            corr_coeff, _ = spearmanr(epoch1_data, epoch2_data)\n",
    "            spearman_channels[ch,i] =corr_coeff\n",
    "\n",
    "    print(f'Number of spearmans correlation calculated: {spearman_channels.shape}')\n",
    "    print(type(spearman_channels))\n",
    "    average_spearmans = np.mean(spearman_channels, axis=1)\n",
    "    plt.figure().set_figwidth(15)\n",
    "    plt.bar(condition.ch_names, average_spearmans)\n",
    "    plt.ylabel(\"Spearman's Rho\")\n",
    "    plt.xlabel(\"Channel\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"(\"+ exp_type + \") \" + \"Within-category spearman's correlation\" + \" (\" + condition_name + \")\")\n",
    "\n",
    "    home_dir = \"/Users/jiontominaga/ThesisProject/\"\n",
    "    fig_save_dir = home_dir + subject_number + exp_type + \"/\"\n",
    "    fig_file_name = \"(\"+ exp_type + \") \" + \"Within-category spearman's correlation\" + \" (\" + condition_name + \")\"+\".png\"\n",
    "    fig_file = fig_save_dir + fig_file_name\n",
    "    plt.savefig(fig_file, dpi=300)\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Plot TOPOMAP for the averaged epoch spearman's correlation for each channel\n",
    "# condition_list = [epochs_condition1, epochs_condition2, epochs_condition3, epochs_condition4, epochs_condition5, epochs_condition6, epochs_condition7, epochs_condition8]\n",
    "#\n",
    "# for condition in condition_list:\n",
    "#     if condition == epochs_condition1:\n",
    "#         condition_name = \"Animal\"\n",
    "#     elif condition == epochs_condition2:\n",
    "#         condition_name = \"Human\"\n",
    "#     elif condition == epochs_condition3:\n",
    "#         condition_name = \"Body Parts\"\n",
    "#     elif condition == epochs_condition4:\n",
    "#         condition_name = \"Vehicle\"\n",
    "#     elif condition == epochs_condition5:\n",
    "#         condition_name = \"Food\"\n",
    "#     elif condition == epochs_condition6:\n",
    "#         condition_name = \"Inanimate\"\n",
    "#     elif condition == epochs_condition7:\n",
    "#         condition_name = \"Man-made Place\"\n",
    "#     elif condition == epochs_condition8:\n",
    "#         condition_name = \"Tools_Artifacts\"\n",
    "#\n",
    "#     print(f'{condition_name} shape: {condition.get_data().shape}')\n",
    "#\n",
    "#     import numpy as np\n",
    "#     from itertools import combinations\n",
    "#     from scipy.stats import spearmanr\n",
    "#     import matplotlib.pyplot as plt\n",
    "#\n",
    "#     # Load epoch data\n",
    "#     arr = condition.get_data()\n",
    "#\n",
    "#     # Get the number of rows\n",
    "#     num_rows = arr.shape[0]\n",
    "#     num_channels = arr.shape[1]\n",
    "#\n",
    "#     # Generate all combinations of epoch indices\n",
    "#     row_combinations = list(combinations(range(num_rows), 2))\n",
    "#     num_combinations = len(row_combinations)\n",
    "#\n",
    "#     # Initialize the array to store the Spearman correlation coefficients\n",
    "#     spearman_channels = np.zeros((num_channels, num_combinations))\n",
    "#\n",
    "#     # Now you can iterate over the combinations and access the corresponding rows\n",
    "#     for ch in range(num_channels):\n",
    "#         for i, combo in enumerate(row_combinations):\n",
    "#             epoch1, epoch2 = combo\n",
    "#             epoch1_data = arr[epoch1][ch]\n",
    "#             epoch2_data = arr[epoch2][ch]\n",
    "#             corr_coeff, _ = spearmanr(epoch1_data, epoch2_data)\n",
    "#             spearman_channels[ch,i] =corr_coeff\n",
    "#\n",
    "#     print(f'Number of spearmans correlation calculated: {spearman_channels.shape}')\n",
    "#     print(type(spearman_channels))\n",
    "#     average_spearmans = np.mean(spearman_channels, axis=1)\n",
    "#     # mne.viz.plot_topomap(data=average_spearmans, )\n",
    "#     # plt.ylabel(\"Spearman's Rho\")\n",
    "#     # plt.xlabel(\"Channel\")\n",
    "#     # plt.xticks(rotation=90)\n",
    "#     # plt.title(\"(\"+ exp_type + \") \" + \"Within-category spearman's correlation\" + \" (\" + condition_name + \")\")\n",
    "#     #\n",
    "#     # home_dir = \"/Users/jiontominaga/ThesisProject/\"\n",
    "#     # fig_save_dir = home_dir + subject_number + exp_type + \"/\"\n",
    "#     # fig_file_name = \"(\"+ exp_type + \") \" + \"Within-category spearman's correlation\" + \" (\" + condition_name + \")\"+\".png\"\n",
    "#     # fig_file = fig_save_dir + fig_file_name\n",
    "#     # plt.savefig(fig_file, dpi=300)\n",
    "#     # plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ###model RDM (WordNet)###\n",
    "# import numpy as np\n",
    "# import sqlite3\n",
    "# from itertools import product\n",
    "# from nltk.corpus import wordnet\n",
    "#\n",
    "# def jpn_path_similarity(word1, word2, cursor):\n",
    "#     cursor.execute(\"SELECT synset FROM sense, word WHERE sense.wordid = word.wordid AND word.lemma=?\", (word1,))\n",
    "#     synsets1 = cursor.fetchall()\n",
    "#\n",
    "#     cursor.execute(\"SELECT synset FROM sense, word WHERE sense.wordid = word.wordid AND word.lemma=?\", (word2,))\n",
    "#     synsets2 = cursor.fetchall()\n",
    "#\n",
    "#     max_similarity = 0\n",
    "#     for synset1, synset2 in product(synsets1, synsets2):\n",
    "#         synset1_id, = synset1\n",
    "#         synset2_id, = synset2\n",
    "#         synset1 = wordnet.synset_from_pos_and_offset(synset1_id[-1], int(synset1_id[:-2]))\n",
    "#         synset2 = wordnet.synset_from_pos_and_offset(synset2_id[-1], int(synset2_id[:-2]))\n",
    "#         similarity = synset1.path_similarity(synset2)\n",
    "#         if similarity is not None and similarity > max_similarity:\n",
    "#             max_similarity = similarity\n",
    "#     return max_similarity\n",
    "#\n",
    "# def compute_rdm(words, cursor):\n",
    "#     n = len(words)\n",
    "#     rdm = np.zeros((n, n))\n",
    "#     for i in range(n):\n",
    "#         for j in range(i + 1, n):\n",
    "#             rdm[i, j] = 1 - jpn_path_similarity(words[i], words[j], cursor)\n",
    "#             rdm[j, i] = rdm[i, j]\n",
    "#     return rdm\n",
    "#\n",
    "# excel_path = '/Users/jiontominaga/ThesisProject/data/word_list/stim_list_final3.xlsx'\n",
    "# list = pd.read_excel(excel_path)\n",
    "#\n",
    "# word_list = list.loc[:, 'lemma']\n",
    "#\n",
    "# word_list = word_list.tolist()\n",
    "# jpn_words = word_list\n",
    "#\n",
    "# # Example list of Japanese words\n",
    "# # jpn_words = ['寿司', '餃子', 'クッキー', 'ナイフ', '櫛', '鉛筆',]\n",
    "#\n",
    "# # Connect to the Japanese WordNet SQLite database\n",
    "# conn = sqlite3.connect('wnjpn.db')\n",
    "# cursor = conn.cursor()\n",
    "#\n",
    "# # Compute the representational dissimilarity matrix\n",
    "# rdm = compute_rdm(jpn_words, cursor)\n",
    "# print(\"Representational Dissimilarity Matrix:\")\n",
    "# print(rdm)\n",
    "#\n",
    "# # Close the connection to the database\n",
    "# conn.close()\n",
    "#\n",
    "# # Set the font that supports Japanese characters\n",
    "# font_path = '/Users/jiontominaga/Library/Fonts/ipaexg.ttf'  # Update this path with the appropriate font file on your system\n",
    "# font_prop = fm.FontProperties(fname=font_path)\n",
    "#\n",
    "# #Set the figure size\n",
    "# plt.figure(figsize=(10,8))\n",
    "#\n",
    "# # Display the RDM using Seaborn\n",
    "# sns.set_theme()\n",
    "# ax = sns.heatmap(rdm, annot=False, cmap='coolwarm', square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, xticklabels=word_list, yticklabels=word_list)\n",
    "# plt.title('modelRDM(6words)_WN.png', fontproperties=font_prop)\n",
    "# ax.set_xticklabels(jpn_words, fontproperties=font_prop, fontsize=12)\n",
    "# ax.set_yticklabels(jpn_words, fontproperties=font_prop, fontsize=12)\n",
    "# ax.grid(which='minor', color='black', linestyle='-', linewidth=1)\n",
    "#\n",
    "# ax.tick_params(labelsize=5)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.yticks(rotation=0)\n",
    "#\n",
    "# # #Add category labels\n",
    "# # for i, word in enumerate(japanese_words):\n",
    "# #     category = word_categories[word]\n",
    "# #     ax.text(\n",
    "# #         i + 0.5, len(japanese_words) - 0.5, category,\n",
    "# #         fontproperties=font_prop, fontsize=12, ha='center', va='center',\n",
    "# #         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.2')\n",
    "# #     )\n",
    "#\n",
    "# plt.tight_layout()\n",
    "#\n",
    "# # Save the plot as a high-resolution PNG image\n",
    "# plt.savefig('modelRDM(80words)_WN.png', dpi=300)\n",
    "#\n",
    "# # Convert the RDM numpy array to a Pandas DataFrame\n",
    "# rdm_df = pd.DataFrame(rdm, index=jpn_words, columns=jpn_words)\n",
    "#\n",
    "# # Save the RDM DataFrame as a CSV file\n",
    "# rdm_df.to_csv('modelRDM(80words)_WN.csv', encoding='utf-8')\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ###modelRDM (Word2Vec)###\n",
    "# ###Here words being loaded are limited to 50,000 words to speed up the computation###\n",
    "#\n",
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from gensim.models import KeyedVectors\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.font_manager as fm\n",
    "#\n",
    "# # Load pre-trained Japanese word embeddings\n",
    "# # japanese_model = KeyedVectors.load_word2vec_format('cc.ja.300.vec', binary=False)\n",
    "# japanese_model = KeyedVectors.load_word2vec_format('cc.ja.300.vec', binary=False, limit=50000)\n",
    "#\n",
    "# # excel_path = '/Users/jiontominaga/ThesisProject/data/word_list/stim_list_final3.xlsx'\n",
    "# # list = pd.read_excel(excel_path)\n",
    "# #\n",
    "# # word_list = list.loc[:, 'lemma']\n",
    "# #\n",
    "# # word_list = word_list.tolist()\n",
    "#\n",
    "# word_list=['寿司', '餃子', 'クッキー', 'ナイフ', '櫛', '鉛筆',]\n",
    "# print(word_list)\n",
    "#\n",
    "# # Input list of Japanese words\n",
    "# japanese_words = word_list\n",
    "#\n",
    "# # #Create a mapping of words to their categories\n",
    "# # word_categories_tuples = {\n",
    "# #     tuple(['蟻', '牛', '象', '鯨', '蛇', '虎', 'ライオン', '蛸']):'Animals',\n",
    "# #     tuple(['先生', '兵士', '医者', '赤ちゃん', 'シェフ', '警官', '娘', '息子']): 'Human',\n",
    "# #     tuple(['腕', '指', '顎', '鼻', '踵', '肘', '膝', '耳']): 'Body Parts',\n",
    "# #     tuple(['ボート', 'バス', '電車', 'トラック', 'バイク', 'ロケット', 'タクシー', '馬車']): 'Vehicle',\n",
    "# #     tuple(['チーズ', '卵', '寿司', 'バナナ', '人参', 'トマト', 'カボチャ', 'ラーメン']): 'Food',\n",
    "# #     tuple(['薔薇', '太陽', '雪', '海', '月', '雨', '桜', '向日葵']): 'Inanimate',\n",
    "# #     tuple(['病院', 'ホテル', 'オフィス', '道', '橋', '駅', '神社', 'コンビニ']): 'Made-made place',\n",
    "# #     tuple(['カメラ', 'フォーク', '鍵', '新聞', '鉛筆', '傘', 'ベッド', 'テレビ']) : 'Artifacts/Tools'}\n",
    "# #\n",
    "# # # Create a new dictionary to map individual words to their categories\n",
    "# # word_categories = {}\n",
    "# # for words, category in word_categories_tuples.items():\n",
    "# #     for word in words:\n",
    "# #         word_categories[word] = category\n",
    "#\n",
    "# # Convert words to their vector representations\n",
    "# vectors = [japanese_model[word] for word in japanese_words]\n",
    "#\n",
    "# # Calculate cosine similarity matrix\n",
    "# cosine_sim_matrix = cosine_similarity(vectors)\n",
    "#\n",
    "# # Compute RDM by subtracting the cosine similarity matrix from 1\n",
    "# rdm = 1 - cosine_sim_matrix\n",
    "# np.fill_diagonal(rdm, 0)\n",
    "# # Set the font that supports Japanese characters\n",
    "# font_path = '/Users/jiontominaga/Library/Fonts/ipaexg.ttf'  # Update this path with the appropriate font file on your system\n",
    "# font_prop = fm.FontProperties(fname=font_path)\n",
    "#\n",
    "# #Set the figure size\n",
    "# plt.figure(figsize=(10,8))\n",
    "#\n",
    "# # Display the RDM using Seaborn\n",
    "# sns.set_theme()\n",
    "# ax = sns.heatmap(rdm, annot=False, cmap='coolwarm', square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, xticklabels=word_list, yticklabels=word_list)\n",
    "# plt.title('modelRDM(6words)_w2v.png', fontproperties=font_prop)\n",
    "# ax.set_xticklabels(japanese_words, fontproperties=font_prop, fontsize=12)\n",
    "# ax.set_yticklabels(japanese_words, fontproperties=font_prop, fontsize=12)\n",
    "# ax.grid(which='minor', color='black', linestyle='-', linewidth=1)\n",
    "#\n",
    "# ax.tick_params(labelsize=5)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.yticks(rotation=0)\n",
    "#\n",
    "# # #Add category labels\n",
    "# # for i, word in enumerate(japanese_words):\n",
    "# #     category = word_categories[word]\n",
    "# #     ax.text(\n",
    "# #         i + 0.5, len(japanese_words) - 0.5, category,\n",
    "# #         fontproperties=font_prop, fontsize=12, ha='center', va='center',\n",
    "# #         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.2')\n",
    "# #     )\n",
    "#\n",
    "# plt.tight_layout()\n",
    "#\n",
    "# # Save the plot as a high-resolution PNG image\n",
    "# plt.savefig('modelRDM(6words)_w2v.png', dpi=300)\n",
    "#\n",
    "# # Convert the RDM numpy array to a Pandas DataFrame\n",
    "# rdm_df = pd.DataFrame(rdm, index=japanese_words, columns=japanese_words)\n",
    "#\n",
    "# # Save the RDM DataFrame as a CSV file\n",
    "# rdm_df.to_csv('modelRDM(6words)_w2v.csv', encoding='utf-8')\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}